{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9758275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "457a5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_raw_data = pd.read_parquet(\"../data/prediction_raw_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2dcfa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"../data/metadata_sample_submission.csv\", index_col=[0])\n",
    "bank_holidays_bcn = pd.read_csv(\"../data/bank_holidays_bcn.csv\", index_col=[0], parse_dates=[\"holiday_date\"])\n",
    "station_information = pd.read_csv(\"../data/station_information.csv\")\n",
    "meteo_data = pd.read_csv(\"../data/valores_booleanos_meteo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbe5c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_data['datetime'] = pd.to_datetime(meteo_data['data']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "meteo_data['datetime'] = pd.to_datetime(meteo_data['datetime'])\n",
    "meteo_data.drop(columns=\"data\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55f8d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create year column\n",
    "metadata[\"year\"]=2024\n",
    "# transform station_id to int\n",
    "metadata[\"station_id\"]=metadata[\"station_id\"].astype(str)\n",
    "\n",
    "metadata[\"date\"]= pd.to_datetime(metadata[[\"year\",\"month\",\"day\"]])\n",
    "metadata[\"datetime\"]= pd.to_datetime(metadata[[\"year\",\"month\",\"day\",\"hour\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf9c945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"is_holidays\"] = metadata[\"date\"].isin(bank_holidays_bcn[\"holiday_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52b6dfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_information[\"station_id\"] = station_information[\"station_id\"].astype(str)\n",
    "metadata =metadata.merge(station_information[[\"station_id\",\"lat\",\"lon\",\"post_code\",\"capacity\"]], on =\"station_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fba00702",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = metadata.merge(meteo_data[[\"datetime\",\"calor\",\"lluvia\"]], on=\"datetime\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feadba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"calor\"] = metadata[\"calor\"].fillna(0).astype(bool)\n",
    "metadata[\"lluvia\"] = metadata[\"lluvia\"].fillna(0).astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0dd886",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46f52dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>altitude</th>\n",
       "      <th>post_code</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>num_docks_available</th>\n",
       "      <th>capacity</th>\n",
       "      <th>percentage_docks_available</th>\n",
       "      <th>datetime</th>\n",
       "      <th>date</th>\n",
       "      <th>is_holidays</th>\n",
       "      <th>calor</th>\n",
       "      <th>lluvia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>41.397978</td>\n",
       "      <td>2.180107</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8013</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>45</td>\n",
       "      <td>0.459259</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>41.397978</td>\n",
       "      <td>2.180107</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8013</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17.416667</td>\n",
       "      <td>45</td>\n",
       "      <td>0.387037</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>41.397978</td>\n",
       "      <td>2.180107</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8013</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.583333</td>\n",
       "      <td>45</td>\n",
       "      <td>0.079630</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>41.397978</td>\n",
       "      <td>2.180107</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8013</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>33.230769</td>\n",
       "      <td>45</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>41.397978</td>\n",
       "      <td>2.180107</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8013</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>27.250000</td>\n",
       "      <td>45</td>\n",
       "      <td>0.605556</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station_id        lat       lon  altitude post_code  year  month  day  hour  \\\n",
       "0          1  41.397978  2.180107      16.0      8013  2020      1    1     0   \n",
       "1          1  41.397978  2.180107      16.0      8013  2020      1    2     0   \n",
       "2          1  41.397978  2.180107      16.0      8013  2020      1    3     0   \n",
       "3          1  41.397978  2.180107      16.0      8013  2020      1    4     0   \n",
       "4          1  41.397978  2.180107      16.0      8013  2020      1    5     0   \n",
       "\n",
       "   num_docks_available  capacity  percentage_docks_available   datetime  \\\n",
       "0            20.666667        45                    0.459259 2020-01-01   \n",
       "1            17.416667        45                    0.387037 2020-01-02   \n",
       "2             3.583333        45                    0.079630 2020-01-03   \n",
       "3            33.230769        45                    0.738462 2020-01-04   \n",
       "4            27.250000        45                    0.605556 2020-01-05   \n",
       "\n",
       "         date  is_holidays  calor  lluvia  \n",
       "0  2020-01-01         True  False   False  \n",
       "1  2020-01-02        False  False   False  \n",
       "2  2020-01-03        False  False   False  \n",
       "3  2020-01-04        False  False   False  \n",
       "4  2020-01-05        False  False   False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d59d085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 399/399 [04:49<00:00,  1.38it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "prediction_data = pd.DataFrame()\n",
    "for s in tqdm(prediction_raw_data.station_id.unique()):\n",
    "    ctx = prediction_raw_data.loc[prediction_raw_data[\"station_id\"] == s, :]\n",
    "    ctx = ctx.sort_values(by=[\"year\", \"month\", \"day\", \"hour\"],\n",
    "                              ignore_index=True)\n",
    "    for lag in range(1, 5):\n",
    "        ctx.loc[:, f\"ctx-{lag}\"] = ctx.loc[:, \"percentage_docks_available\"].shift(lag)\n",
    "\n",
    "    ctx = ctx.iloc[4::5]\n",
    "\n",
    "    prediction_data = pd.concat([prediction_data, ctx], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "322072c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data.drop(columns=[\"datetime\",\"date\",\"altitude\", \"num_docks_available\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d4db2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data[\"station_id\"]= prediction_data[\"station_id\"].astype(str)\n",
    "prediction_data[\"post_code\"]= prediction_data[\"post_code\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77d7590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data.dropna(subset=[\"percentage_docks_available\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0594d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data.dropna(subset=[\"ctx-1\",\"ctx-2\", \"ctx-3\", \"ctx-4\"],how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac97f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = prediction_data[(prediction_data[\"year\"]<=2023) & (prediction_data[\"month\"]<8)]\n",
    "validation= prediction_data[(prediction_data[\"year\"]==2023) & (prediction_data[\"month\"]>=8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6944d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(columns=\"percentage_docks_available\")\n",
    "y_train = train[[\"percentage_docks_available\"]]\n",
    "\n",
    "\n",
    "x_validation = validation.drop(columns=\"percentage_docks_available\")\n",
    "y_validation = validation[[\"percentage_docks_available\"]]\n",
    "\n",
    "\n",
    "metadata=metadata[train.columns.drop(\"percentage_docks_available\").tolist()]\n",
    "metadata[\"post_code\"]= metadata[\"post_code\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0506e8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicalEncoder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, max_val):\n",
    "        self.max_val = max_val\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for column in X.columns:\n",
    "            X[column + \"_sin\"] = np.sin(2 * np.pi * X[column] / self.max_val)\n",
    "            X[column + \"_cos\"] = np.cos(2 * np.pi * X[column] / self.max_val)\n",
    "            X.drop(columns=column, inplace=True)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e4af222",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), [\"station_id\", \"post_code\"]),\n",
    "        ('hour_econder', CyclicalEncoder(max_val=24), [\"hour\"]),\n",
    "        ('day_econder', CyclicalEncoder(max_val=31), [\"day\"]),\n",
    "        \n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b84c86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = transformer.fit_transform(x_train)\n",
    "x_validation = transformer.transform(x_validation)\n",
    "metadata = transformer.transform(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e012f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a7ec67d",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[15:22:19] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\common\\io.h:232: bad_malloc: Failed to allocate 687081395 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBRegressor(objective \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg:squarederror\u001b[39m\u001b[38;5;124m'\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, eta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, subsample\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m, tree_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhist\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     11\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_validation)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1055\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[0;32m   1054\u001b[0m     evals_result: TrainingCallback\u001b[38;5;241m.\u001b[39mEvalsLog \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1055\u001b[0m     train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1056\u001b[0m         missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1057\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1058\u001b[0m         y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m   1059\u001b[0m         group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1060\u001b[0m         qid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1061\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1062\u001b[0m         base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   1063\u001b[0m         feature_weights\u001b[38;5;241m=\u001b[39mfeature_weights,\n\u001b[0;32m   1064\u001b[0m         eval_set\u001b[38;5;241m=\u001b[39meval_set,\n\u001b[0;32m   1065\u001b[0m         sample_weight_eval_set\u001b[38;5;241m=\u001b[39msample_weight_eval_set,\n\u001b[0;32m   1066\u001b[0m         base_margin_eval_set\u001b[38;5;241m=\u001b[39mbase_margin_eval_set,\n\u001b[0;32m   1067\u001b[0m         eval_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1068\u001b[0m         eval_qid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1069\u001b[0m         create_dmatrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_dmatrix,\n\u001b[0;32m   1070\u001b[0m         enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_categorical,\n\u001b[0;32m   1071\u001b[0m         feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1072\u001b[0m     )\n\u001b[0;32m   1073\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1075\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:521\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_evaluation_matrices\u001b[39m(\n\u001b[0;32m    502\u001b[0m     missing: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[0;32m    503\u001b[0m     X: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    517\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[0;32m    518\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m    519\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;124;03m    way.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 521\u001b[0m     train_dmatrix \u001b[38;5;241m=\u001b[39m create_dmatrix(\n\u001b[0;32m    522\u001b[0m         data\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    523\u001b[0m         label\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    524\u001b[0m         group\u001b[38;5;241m=\u001b[39mgroup,\n\u001b[0;32m    525\u001b[0m         qid\u001b[38;5;241m=\u001b[39mqid,\n\u001b[0;32m    526\u001b[0m         weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    527\u001b[0m         base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m    528\u001b[0m         feature_weights\u001b[38;5;241m=\u001b[39mfeature_weights,\n\u001b[0;32m    529\u001b[0m         missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[0;32m    530\u001b[0m         enable_categorical\u001b[38;5;241m=\u001b[39menable_categorical,\n\u001b[0;32m    531\u001b[0m         feature_types\u001b[38;5;241m=\u001b[39mfeature_types,\n\u001b[0;32m    532\u001b[0m         ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    533\u001b[0m     )\n\u001b[0;32m    535\u001b[0m     n_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(eval_set)\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:958\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[1;34m(self, ref, **kwargs)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _can_use_qdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_method) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbooster \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 958\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m QuantileDMatrix(\n\u001b[0;32m    959\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, ref\u001b[38;5;241m=\u001b[39mref, nthread\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, max_bin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_bin\n\u001b[0;32m    960\u001b[0m         )\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[0;32m    962\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:1529\u001b[0m, in \u001b[0;36mQuantileDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m   1510\u001b[0m         info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1511\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1522\u001b[0m         )\n\u001b[0;32m   1523\u001b[0m     ):\n\u001b[0;32m   1524\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1525\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf data iterator is used as input, data like label should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1526\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified as batch argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1527\u001b[0m         )\n\u001b[1;32m-> 1529\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init(\n\u001b[0;32m   1530\u001b[0m     data,\n\u001b[0;32m   1531\u001b[0m     ref\u001b[38;5;241m=\u001b[39mref,\n\u001b[0;32m   1532\u001b[0m     label\u001b[38;5;241m=\u001b[39mlabel,\n\u001b[0;32m   1533\u001b[0m     weight\u001b[38;5;241m=\u001b[39mweight,\n\u001b[0;32m   1534\u001b[0m     base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   1535\u001b[0m     group\u001b[38;5;241m=\u001b[39mgroup,\n\u001b[0;32m   1536\u001b[0m     qid\u001b[38;5;241m=\u001b[39mqid,\n\u001b[0;32m   1537\u001b[0m     label_lower_bound\u001b[38;5;241m=\u001b[39mlabel_lower_bound,\n\u001b[0;32m   1538\u001b[0m     label_upper_bound\u001b[38;5;241m=\u001b[39mlabel_upper_bound,\n\u001b[0;32m   1539\u001b[0m     feature_weights\u001b[38;5;241m=\u001b[39mfeature_weights,\n\u001b[0;32m   1540\u001b[0m     feature_names\u001b[38;5;241m=\u001b[39mfeature_names,\n\u001b[0;32m   1541\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39mfeature_types,\n\u001b[0;32m   1542\u001b[0m     enable_categorical\u001b[38;5;241m=\u001b[39menable_categorical,\n\u001b[0;32m   1543\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:1590\u001b[0m, in \u001b[0;36mQuantileDMatrix._init\u001b[1;34m(self, data, ref, enable_categorical, **meta)\u001b[0m\n\u001b[0;32m   1588\u001b[0m it\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[0;32m   1589\u001b[0m \u001b[38;5;66;03m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[1;32m-> 1590\u001b[0m _check_call(ret)\n\u001b[0;32m   1591\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;241m=\u001b[39m handle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:282\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \n\u001b[0;32m    273\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [15:22:19] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\common\\io.h:232: bad_malloc: Failed to allocate 687081395 bytes."
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the model\n",
    "model = xgb.XGBRegressor(objective ='reg:squarederror', n_estimators=50, max_depth=5, eta=0.1, subsample=0.7, tree_method='hist')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(x_validation)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_validation, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c642ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5f92f6",
   "metadata": {},
   "source": [
    "# PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c687cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
